{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1_FvED3zDyqBXb29Vdw180D25lFbRgZMC","authorship_tag":"ABX9TyNC85UJTUfl0wBb11StBlF1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["pip install idx2numpy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZcU8uFcdn-X","executionInfo":{"status":"ok","timestamp":1665600726809,"user_tz":-60,"elapsed":2995,"user":{"displayName":"Seoirse Murray","userId":"17347059477141132429"}},"outputId":"581f09f9-57ab-44e2-a7d3-32d07b1e8dde"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: idx2numpy in /usr/local/lib/python3.7/dist-packages (1.2.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.21.6)\n"]}]},{"cell_type":"code","execution_count":39,"metadata":{"id":"5BBpeVyNcU8e","executionInfo":{"status":"ok","timestamp":1665600726811,"user_tz":-60,"elapsed":23,"user":{"displayName":"Seoirse Murray","userId":"17347059477141132429"}}},"outputs":[],"source":["import os\n","from turtle import forward\n","import torch\n","from torch import TensorType, nn\n","from os.path import exists\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import torchvision.utils as vutils\n","import math\n","import torch.nn.functional as F\n","import random\n","from torch.utils.data import DataLoader\n","import time\n","import torch.optim as optim\n","\n","import idx2numpy\n","\n","def plot_several(data,titles):\n","    m = data.shape[0]\n","    print(m)\n","    fig, axes = plt.subplots(ncols = m,sharex=False, sharey=True, figsize=(10, 4))\n","    for i in range(m):\n","        #print(titles[i])\n","        axes[i].set_title(titles[i])\n","        axes[i].imshow(data[i,0,:,:], cmap='gray')\n","        axes[i].get_xaxis().set_visible(False)\n","        axes[i].get_yaxis().set_visible(False)\n","        \n","    plt.show()\n","\n","def import_data(imageFile,labelsFile):\n","    data = idx2numpy.convert_from_file(imageFile)\n","    # arr is a np.ndarray type of object of shape (60000, 28, 28)\n","    labels = idx2numpy.convert_from_file(labelsFile)\n","    # labels is a np.ndarray type of object of shape (60000, )\n","    data = (torch.tensor(data).float() - 128)/128\n","    #normalises the data to the interval [-1,1]\n","    labels = torch.tensor(labels).float()\n","\n","    dataShape = torch.reshape(data,(-1,1,28,28))\n","    # We reshape to allow for a channel \"1\" which makes working with the convolution functions later easier\n","    #print(data[0,:,:])\n","    return dataShape, labels\n","\n","class SinusoidalPositionEmbeddings(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.dim = dim\n","\n","    def forward(self, time):\n","        device = time.device\n","        half_dim = self.dim // 2\n","        embeddings = math.log(10000) / (half_dim - 1)\n","        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n","        embeddings = time[:, None] * embeddings[None, :]\n","        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n","        return embeddings\n","\n","def beta_schedule(T,s=0.008):\n","    # from https://arxiv.org/pdf/2102.09672.pdf pg 4\n","    steps = T + 1\n","    x = torch.linspace(0,T,steps)\n","    alpha = torch.cos(0.5*math.pi*((x/T)+s)/(1+s))**2\n","    alpha = alpha/alpha[0]\n","    beta = 1 - (alpha[1:]/(alpha[:-1]))\n","    return torch.clamp(beta,0.0001,0.9999)\n","    \n","def extract(a, t, x_shape):\n","    batch_size = t.shape[0]\n","    t = t.type(torch.int64)\n","    out = a.gather(-1, t.cuda())\n","    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n","\n","# forward diffusion (using the nice property)\n","def q_sample(x_start, t,sqrt_alphas_cumprod,sqrt_one_minus_alphas_cumprod, noise=None):\n","    if noise is None:\n","        noise = torch.randn_like(x_start) #Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1\n","\n","    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n","    sqrt_one_minus_alphas_cumprod_t = extract(\n","        sqrt_one_minus_alphas_cumprod, t, x_start.shape\n","    )\n","    #print(sqrt_alphas_cumprod_t,sqrt_one_minus_alphas_cumprod_t)\n","    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n","\n","def p_losses(denoise_model, x_start, t,sqrt_alphas_cumprod,sqrt_one_minus_alphas_cumprod, noise = None):\n","    if noise is None:\n","        noise = torch.randn_like(x_start)\n","\n","    x_noisy = q_sample(x_start, t,sqrt_alphas_cumprod,sqrt_one_minus_alphas_cumprod, noise=noise)\n","\n","    predicted_noise = denoise_model(x_noisy, t)\n","\n","    loss = F.smooth_l1_loss(noise, predicted_noise) #Creates a criterion that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise. It is less sensitive to outliers than torch.nn.MSELoss and in some cases prevents exploding gradients (e.g. see the paper Fast R-CNN by Ross Girshick).\n","    return loss\n","\n","class Encoder(nn.Module):\n","    def __init__(self,shapeIn,nLatent):\n","        super(Encoder, self).__init__()\n","        self.shapeIn = shapeIn\n","        self.nLatent = nLatent\n","\n","        self.enc1 = self.encoder_block(1,10,3,2,1)\n","        self.enc2 = self.encoder_block(10,20,3,2,1)\n","        self.lin1 = self.linear(980,nLatent)\n","        self.lin2 = self.linear(980,nLatent)\n","\n","    def encoder_block(self, input_channel, output_channel, kernel_size, stride, padding):\n","        return nn.Sequential(\n","                nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),\n","                #nn.BatchNorm2d(output_channel),\n","                nn.ReLU(0.2)#,inplace=True),\n","            )   \n","\n","    def linear(self,nIn,nOut):\n","        return nn.Sequential(\n","            nn.Linear(nIn,nOut),\n","            #nn.BatchNorm2d(output_channel),\n","            nn.ReLU(0.2)#,inplace=True)\n","        )\n","\n","    def forward(self,z):\n","        #print(z.shape)\n","        z = self.enc1(z)\n","        #print(z.shape)\n","        z = self.enc2(z)\n","        #print(z.shape)\n","        z = z.view(-1, 7*7*20)\n","        #print(z.shape)\n","        mu = self.lin1(z)\n","        logVar = self.lin2(z)\n","        #print(mu.shape,logVar.shape)\n","        return mu, logVar\n","\n","class Decoder(nn.Module):\n","    def __init__(self,shapeOut,nLatent):\n","        super(Decoder, self).__init__()\n","\n","        self.linear1 = self.linear(nLatent,7*7*20)\n","        self.dec1 = self.decoder_block(20,10,3,3,2)\n","        self.dec2 = self.decoder_block(10,1,2,2,3)\n","\n","    def decoder_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(input_channel, output_channel, kernel_size, stride, padding),\n","            #nn.BatchNorm2d(output_channel),\n","            nn.LeakyReLU(0.2)#,inplace=True),\n","        )   \n","\n","    def linear(self,nLatent,nOut):\n","        return nn.Sequential(\n","                nn.Linear(nLatent,nOut),\n","                #nn.BatchNorm2d(output_channel),\n","                nn.ReLU(0.2)#,inplace=True),\n","            )\n","\n","    def forward(self,z):\n","        #print(z.shape)\n","        z = self.linear1(z)\n","        #print(z.shape)\n","        z = z.view(-1,20,7,7)\n","        z = self.dec1(z)\n","        #print(z.shape)\n","        z = self.dec2(z)\n","        #print(z.shape)\n","        return z\n","    \n","class Diffusion(nn.Module):\n","    def __init__(self,shapeIn,nLatent):\n","        super(Diffusion, self).__init__()\n","\n","        self.encoder = Encoder(shapeIn,nLatent)\n","        self.decoder = Decoder(shapeIn,nLatent) \n","        # not needed in first instance?\n","        # self.time_dimen = nn.Sequential(\n","        #         SinusoidalPositionEmbeddings(dim),\n","        #         nn.Linear(dim, time_dim),\n","        #         nn.GELU(),\n","        #         nn.Linear(time_dim, time_dim),\n","        #     )\n","\n","    def reparameterize(self, mu, logVar):\n","        #Reparameterization takes in the input mu and logVar and sample the mu + std * eps\n","        std = torch.exp(logVar/2)\n","        eps = torch.randn_like(std)\n","        return mu + std * eps\n","\n","    def forward(self, z, t):\n","        ### todo - implement time awareness \n","        mu,logVar = self.encoder.forward(z)\n","        z = self.reparameterize(mu, logVar)\n","        return self.decoder.forward(z)\n","    \n","\n","def sample_model(diffusion,x,T,betas,sqrt_recip_alphas,sqrt_one_minus_alphas_cumprod,posterior_variance,device):\n","    # we want to sample our model to check progress\n","    def sample_timestep(diffusion,x,t,betas,sqrt_recip_alphas,sqrt_one_minus_alphas_cumprod,posterior_variance,device):\n","        betas_t = extract(betas,t, x.shape).to(device)\n","        sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x.shape).to(device)\n","        sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape).to(device)\n","\n","        model_mean = sqrt_recip_alphas_t * (x - betas_t * diffusion.forward(x, t) / sqrt_one_minus_alphas_cumprod_t)\n","        model_mean = model_mean.to(device)\n","        if t == 0:\n","            return model_mean\n","        else:\n","            posterior_variance_t = extract(posterior_variance, t, x.shape).to(device)\n","            noise = torch.randn_like(x).to(device)\n","            # Algorithm 2 line 4:\n","            return model_mean + torch.sqrt(posterior_variance_t) * noise\n","\n","    xt = x\n","    for t in range(T):\n","        xt = sample_timestep(diffusion,xt,torch.tensor([t]),betas,sqrt_recip_alphas,sqrt_one_minus_alphas_cumprod,posterior_variance,device)\n","\n","\n","    return xt\n"]},{"cell_type":"code","source":["\n","def backpropogate(epochs,dataloader,diffusion,optimiser,steps,losses,T,batch_size,device,sqrt_alphas_cumprod,sqrt_one_minus_alphas_cumprod):\n","    \n","    if(len(steps) != 0):\n","        step = steps[-1]\n","    else:\n","        step =0\n","\n","    for epoch in range(epochs):\n","        epoch_start_time = time.time()\n","        for i, data in enumerate(dataloader, 0):\n","            data=data.to(device)\n","            steps.append(step)\n","            step += 1\n","\n","            optimiser.zero_grad()\n","            #################\n","            t = torch.randint(0,T,(batch_size,),device = device)\n","            loss = p_losses(diffusion,data,t,sqrt_alphas_cumprod,sqrt_one_minus_alphas_cumprod)\n","\n","            loss.backward()\n","            optimiser.step()\n","            losses.append(loss.item())\n","\n","            if i % 200 == 0:\n","                print('[%d/%d][%d/%d]\\tLoss: %.4f'\n","              % (epoch, epochs, i, len(dataloader),\n","                  losses[-1]))\n","        print('After epoch %i, the loss is %.4f' % (epoch,losses[-1]))\n","\n","    return diffusion, steps, losses\n"],"metadata":{"id":"7SmVcFnrfOpX","executionInfo":{"status":"ok","timestamp":1665601016285,"user_tz":-60,"elapsed":456,"user":{"displayName":"Seoirse Murray","userId":"17347059477141132429"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["fileFolder = '/content/drive/MyDrive/Colab Notebooks/train_classifier'\n","\n","trainingFiles = [fileFolder + '/train-images-idx3-ubyte',fileFolder + '/train-labels-idx1-ubyte']\n","testFiles = [fileFolder + '/train-images-idx3-ubyte',fileFolder + '/train-labels-idx1-ubyte']\n","modelPath = fileFolder + '/diffusion.pt'\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")\n","data,numbers = import_data(trainingFiles[0],trainingFiles[1])\n","\n","\n","T = 200\n","betas = beta_schedule(T,0.008).to(device)\n","alphas = 1.-betas\n","alphas_cumprod = torch.cumprod(alphas,-1) # cumprod is all the products of previous elements\n","alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n","sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n","plot_noise = False\n","\n","\n","# calculations for diffusion q(x_t | x_{t-1}) and others\n","sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod).to(device)\n","sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod).to(device)\n","\n","# calculations for posterior q(x_{t-1} | x_t, x_0)\n","posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n","\n","############### plotting data #############\n","i = random.randint(0,60000)\n","x = data[i:i+1].to(device)\n","xs = x\n","ts = np.linspace(0,199,5,dtype = int)\n","for t in ts[1:]:\n","    x_noise = q_sample(x, torch.tensor([t]).to(device),sqrt_alphas_cumprod,sqrt_one_minus_alphas_cumprod, noise=None)\n","    xs = torch.cat((xs,x_noise),0)\n","if plot_noise:\n","    plot_several(xs,ts)\n","##########\n","\n","diffusion = Diffusion([28,28],100).to(device)\n","\n","steps = []\n","losses = []\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rEgJAdeSeviK","executionInfo":{"status":"ok","timestamp":1665601033658,"user_tz":-60,"elapsed":376,"user":{"displayName":"Seoirse Murray","userId":"17347059477141132429"}},"outputId":"8c334473-ba3d-467d-8498-1e3ba1b437a2"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"code","source":["batch_size = 128\n","epochs = 10\n","learning_rate = 1e-3\n","data_subset = 60000\n","\n","\n","dataloader = DataLoader(data[0:data_subset,:,:,:], batch_size=batch_size, shuffle=True, drop_last=True )\n","optimiser = optim.Adam(diffusion.parameters(), lr=learning_rate)"],"metadata":{"id":"ME0YeMp1fDww","executionInfo":{"status":"ok","timestamp":1665601037684,"user_tz":-60,"elapsed":411,"user":{"displayName":"Seoirse Murray","userId":"17347059477141132429"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["diffusion, steps, losses = backpropogate(epochs,dataloader,diffusion,optimiser,steps,losses,T,batch_size,device,sqrt_alphas_cumprod,sqrt_one_minus_alphas_cumprod)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5mge_I2fJnd","executionInfo":{"status":"ok","timestamp":1665601061675,"user_tz":-60,"elapsed":22556,"user":{"displayName":"Seoirse Murray","userId":"17347059477141132429"}},"outputId":"f27015a4-6e51-4cf3-8adf-660f66d3f57a"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["[0/10][0/468]\tLoss: 0.4262\n","[0/10][200/468]\tLoss: 0.4247\n","[0/10][400/468]\tLoss: 0.4155\n","After epoch 0, the loss is 0.4134\n","[1/10][0/468]\tLoss: 0.4129\n","[1/10][200/468]\tLoss: 0.4147\n","[1/10][400/468]\tLoss: 0.4106\n","After epoch 1, the loss is 0.4087\n","[2/10][0/468]\tLoss: 0.4142\n","[2/10][200/468]\tLoss: 0.4098\n","[2/10][400/468]\tLoss: 0.4069\n","After epoch 2, the loss is 0.4072\n","[3/10][0/468]\tLoss: 0.4086\n","[3/10][200/468]\tLoss: 0.4066\n","[3/10][400/468]\tLoss: 0.4061\n","After epoch 3, the loss is 0.4092\n","[4/10][0/468]\tLoss: 0.4077\n","[4/10][200/468]\tLoss: 0.4060\n","[4/10][400/468]\tLoss: 0.4065\n","After epoch 4, the loss is 0.4058\n","[5/10][0/468]\tLoss: 0.4028\n","[5/10][200/468]\tLoss: 0.4047\n","[5/10][400/468]\tLoss: 0.4035\n","After epoch 5, the loss is 0.4035\n","[6/10][0/468]\tLoss: 0.4047\n","[6/10][200/468]\tLoss: 0.4011\n","[6/10][400/468]\tLoss: 0.4055\n","After epoch 6, the loss is 0.4045\n","[7/10][0/468]\tLoss: 0.4046\n","[7/10][200/468]\tLoss: 0.4018\n","[7/10][400/468]\tLoss: 0.3991\n","After epoch 7, the loss is 0.4045\n","[8/10][0/468]\tLoss: 0.4015\n","[8/10][200/468]\tLoss: 0.4017\n","[8/10][400/468]\tLoss: 0.4006\n","After epoch 8, the loss is 0.4024\n","[9/10][0/468]\tLoss: 0.4021\n","[9/10][200/468]\tLoss: 0.4001\n","[9/10][400/468]\tLoss: 0.4032\n","After epoch 9, the loss is 0.4012\n"]}]},{"cell_type":"code","source":["\n","x = torch.rand(1,1,28,28).to(device)\n","x_samp = sample_model(diffusion,x,T,betas,sqrt_recip_alphas,sqrt_one_minus_alphas_cumprod,posterior_variance,device)\n","x_out = diffusion.forward(x,0).detach().to('cpu')\n","x = x.to('cpu')\n","plot_several(torch.cat((x,x_out),0),[\"Original\",\"Generated\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285},"id":"JUOTsmqpfV7z","executionInfo":{"status":"ok","timestamp":1665601069229,"user_tz":-60,"elapsed":418,"user":{"displayName":"Seoirse Murray","userId":"17347059477141132429"}},"outputId":"87b9a730-7269-4289-acfb-6e80f2a02a23"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}